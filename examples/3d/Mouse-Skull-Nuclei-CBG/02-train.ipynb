{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from EmbedSeg.train import begin_training\n",
    "from EmbedSeg.utils.create_dicts import create_dataset_dict, create_model_dict, create_loss_dict, create_configs\n",
    "import torch\n",
    "from matplotlib.colors import ListedColormap\n",
    "import json\n",
    "#%matplotlib tk # comment this line, if running in the headless mode "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the path to `train`, `val` crops and the type of `center` embedding which we would like to train the network for:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train-val images, masks and center-images will be accessed from the path specified by `data_dir` and `project-name`.\n",
    "<a id='center'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Name chosen as : Mouse-Skull-Nuclei-CBG. \n",
      "Train-Val images-masks-center-images will be accessed from : crops\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'crops'\n",
    "project_name = 'Mouse-Skull-Nuclei-CBG'\n",
    "center = 'medoid' # 'centroid', 'medoid'\n",
    "\n",
    "print(\"Project Name chosen as : {}. \\nTrain-Val images-masks-center-images will be accessed from : {}\".format(project_name, data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial Embedding Location chosen as : medoid\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert center in {'medoid', 'centroid'}\n",
    "    print(\"Spatial Embedding Location chosen as : {}\".format(center))\n",
    "except AssertionError as e:\n",
    "    e.args += ('Please specify center as one of : {\"medoid\", \"centroid\"}', 42)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain properties of the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we read the `dataset.json` file prepared in the `01-data` notebook previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('data_properties.json'): \n",
    "    with open('data_properties.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        one_hot, data_type, foreground_weight, n_z, n_y, n_x, pixel_size_z_microns, pixel_size_x_microns = data['one_hot'], data['data_type'], float(data['foreground_weight']), int(data['n_z']), int(data['n_y']), int(data['n_x']), float(data['pixel_size_z_microns']), float(data['pixel_size_x_microns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_factor = 65535 if data_type=='16-bit' else 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify training dataset-related parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hints: \n",
    "* The `train_size` attribute indicates the number of image-mask paired examples which the network would see in one complete epoch. Ideally this should be the number of `train` image crops. For the `Mouse-Skull-Nuclei-CBG` dataset, we obtain ~ 128 crops, since this is a small number, we set `train_size` to double the size 256. \n",
    "* The effective batch size is determined as a product of the attributes `train_batch_size` and `virtual_train_batch_multiplier`. For example, one could set a small `batch_size` say equal to 2 (to fit in one's GPU memory), and a large `virtual_train_batch_multiplier` say equal to 8, to get an effective batch size equal to 16. \n",
    "\n",
    "In the cell after this one, a `train_dataset_dict` dictionary is generated from the parameters specified here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 256\n",
    "train_batch_size = 2 \n",
    "virtual_train_batch_multiplier = 8 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `train_dataset_dict` dictionary  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`train_dataset_dict` dictionary successfully created with: \n",
      " -- train images accessed from crops/Mouse-Skull-Nuclei-CBG/train/images, \n",
      " -- number of images per epoch equal to 256, \n",
      " -- batch size set at 2, \n",
      " -- virtual batch multiplier set as 8, \n",
      " -- normalization_factor set as 65535, \n",
      " -- one_hot set as False, \n"
     ]
    }
   ],
   "source": [
    "train_dataset_dict = create_dataset_dict(data_dir = data_dir, \n",
    "                                         project_name = project_name,  \n",
    "                                         center = center, \n",
    "                                         size = train_size, \n",
    "                                         batch_size = train_batch_size, \n",
    "                                         virtual_batch_multiplier = virtual_train_batch_multiplier, \n",
    "                                         normalization_factor= normalization_factor,\n",
    "                                         type = 'train',\n",
    "                                         name = '3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify validation dataset-related parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hints:\n",
    "* The size attribute indicates the number of image-mask paired examples which the network would see in one complete epoch. Here, it is recommended to set `val_size` equal to the total number of validation image crops. For example, for the `Mouse-Skull-NucleiCBG` dataset, we notice ~22 validation crops, since this is a small number, hence we set `val_size = 176`.\n",
    "* The effective batch size is determined as a product of the attributes `val_batch_size` and `virtual_val_batch_multiplier`. Here at times, it is okay to set a higher effective batch size for the validation dataset than the train dataset, since evaluating on validation data consumes lesser GPU memory.\n",
    "\n",
    "In the cell after this one, a `val_dataset_dict` dictionary is generated from the parameters specified here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 176\n",
    "val_batch_size = 16\n",
    "virtual_val_batch_multiplier = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `val_dataset_dict` dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`val_dataset_dict` dictionary successfully created with: \n",
      " -- val images accessed from crops/Mouse-Skull-Nuclei-CBG/val/images, \n",
      " -- number of images per epoch equal to 176, \n",
      " -- batch size set at 16, \n",
      " -- virtual batch multiplier set as 1, \n",
      " -- normalization_factor set as 65535, \n",
      " -- one_hot set as False, \n"
     ]
    }
   ],
   "source": [
    "val_dataset_dict = create_dataset_dict(data_dir = data_dir, \n",
    "                                       project_name = project_name, \n",
    "                                       center = center, \n",
    "                                       size = val_size, \n",
    "                                       batch_size = val_batch_size, \n",
    "                                       virtual_batch_multiplier = virtual_val_batch_multiplier,\n",
    "                                       normalization_factor= normalization_factor,\n",
    "                                       type ='val',\n",
    "                                       name ='3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify model-related parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hints:\n",
    "* Set the `input_channels` attribute equal to the number of channels in the input images. \n",
    "* Set the `num_classes = [6, 1]` for `3d` training and `num_classes = [4, 1]` for `2d` training\n",
    "<br>(here, 6 implies the offsets and bandwidths in x, y and z dimensions and 1 implies the `seediness` value per pixel)\n",
    "\n",
    "In the cell after this one, a `model_dataset_dict` dictionary is generated from the parameters specified here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 1\n",
    "num_classes = [6, 1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `model_dict` dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`model_dict` dictionary successfully created with: \n",
      " -- num of classes equal to 1, \n",
      " -- input channels equal to [6, 1], \n",
      " -- name equal to 3d\n"
     ]
    }
   ],
   "source": [
    "model_dict = create_model_dict(input_channels = input_channels,\n",
    "                              num_classes = num_classes,\n",
    "                              name = '3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `loss_dict` dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`loss_dict` dictionary successfully created with: \n",
      " -- foreground weight equal to 3.174, \n",
      " -- w_inst equal to 1, \n",
      " -- w_var equal to 10, \n",
      " -- w_seed equal to 1\n"
     ]
    }
   ],
   "source": [
    "loss_dict = create_loss_dict(n_sigma = 3, foreground_weight = foreground_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify additional parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hints:\n",
    "* The `n_epochs` attribute determines how long the training should proceed. In general for reasonable results, you should atleast train for longer than 50 epochs.\n",
    "* The `display` attribute, if set to True, allows you to see the network predictions as the training proceeds. \n",
    "* The `display_embedding` attribute, if set to True, allows you to see some sample embedding as the training proceeds. Setting this to False leads to faster training times.\n",
    "* The `save_dir` attribute identifies the location where the checkpoints and loss curve details are saved. \n",
    "* If one wishes to **resume training** from a previous checkpoint, they could point `resume_path` attribute appropriately. For example, one could set `resume_path = './experiment/Mouse-Organoid-Cells-CBG-demo/checkpoint.pth'` to resume training from the last checkpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "display = False\n",
    "display_embedding = False\n",
    "save_dir = os.path.join('experiment', project_name+'-'+'demo')\n",
    "resume_path  = save_dir+'/checkpoint.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell after this one, a `configs` dictionary is generated from the parameters specified here!\n",
    "<a id='resume'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the  `configs` dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`configs` dictionary successfully created with: \n",
      " -- n_epochs equal to 200, \n",
      " -- display equal to False, \n",
      " -- save_dir equal to experiment/Mouse-Skull-Nuclei-CBG-demo, \n",
      " -- n_z equal to 128, \n",
      " -- n_y equal to 512, \n",
      " -- n_x equal to 512, \n",
      " -- one_hot equal to False, \n"
     ]
    }
   ],
   "source": [
    "configs = create_configs(n_epochs = n_epochs,\n",
    "                         display = display, \n",
    "                         display_embedding = display_embedding,\n",
    "                         resume_path = resume_path, \n",
    "                         save_dir = save_dir, \n",
    "                         n_z = n_z,\n",
    "                         n_y = n_y, \n",
    "                         n_x = n_x,\n",
    "                         anisotropy_factor = pixel_size_z_microns/pixel_size_x_microns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the next cell would begin the training. \n",
    "\n",
    "If `display` attribute was set to `True` above, then you would see the network predictions at every $n^{th}$ step (equals 5, by default) on training and validation images. \n",
    "\n",
    "Going clockwise from top-left is \n",
    "\n",
    "    * the raw-image which needs to be segmented, \n",
    "    * the corresponding ground truth instance mask, \n",
    "    * the network predicted instance mask, and \n",
    "    * (if display_embedding = True) from each object instance, 5 pixels are randomly selected (indicated with `+`), their embeddings are plotted (indicated with `.`) and the predicted margin for that object is visualized as an axis-aligned ellipse centred on the ground-truth - center (indicated with `x`)  for that object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-D `train` dataloader created! Accessing data from crops/Mouse-Skull-Nuclei-CBG/train/\n",
      "Number of images in `train` directory is 128\n",
      "Number of instances in `train` directory is 128\n",
      "Number of center images in `train` directory is 128\n",
      "*************************\n",
      "3-D `val` dataloader created! Accessing data from crops/Mouse-Skull-Nuclei-CBG/val/\n",
      "Number of images in `val` directory is 22\n",
      "Number of instances in `val` directory is 22\n",
      "Number of center images in `val` directory is 22\n",
      "*************************\n",
      "Creating branched erfnet 3d with [6, 1] classes\n",
      "initialize last layer with size:  torch.Size([16, 6, 2, 2, 2])\n",
      "Created spatial emb loss function with: n_sigma: 3, foreground_weight: 3.173831196077842\n",
      "*************************\n",
      "Created logger with keys:  ('train', 'val', 'iou')\n",
      "Resuming model from experiment/Mouse-Skull-Nuclei-CBG-demo/checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 120\n",
      "learning rate: 0.00021919164527704348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:39<00:00,  1.25s/it]\n",
      "100%|██████████| 11/11 [00:53<00:00,  4.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.45\n",
      "===> val loss: 0.48, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 121\n",
      "learning rate: 0.0002167241909659091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:35<00:00,  1.21s/it]\n",
      "100%|██████████| 11/11 [00:51<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.45\n",
      "===> val loss: 0.47, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 122\n",
      "learning rate: 0.00021425361122954587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:34<00:00,  1.21s/it]\n",
      "100%|██████████| 11/11 [00:50<00:00,  4.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.45\n",
      "===> val loss: 0.48, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 123\n",
      "learning rate: 0.00021177986196077483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:32<00:00,  1.19s/it]\n",
      "100%|██████████| 11/11 [00:50<00:00,  4.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.43\n",
      "===> val loss: 0.47, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 124\n",
      "learning rate: 0.00020930289784861406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:32<00:00,  1.19s/it]\n",
      "100%|██████████| 11/11 [00:50<00:00,  4.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.44\n",
      "===> val loss: 0.49, val iou: 0.80\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 125\n",
      "learning rate: 0.0002068226723291381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:33<00:00,  1.20s/it]\n",
      "100%|██████████| 11/11 [00:51<00:00,  4.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.44\n",
      "===> val loss: 0.47, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 126\n",
      "learning rate: 0.00020433913753364945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:35<00:00,  1.21s/it]\n",
      "100%|██████████| 11/11 [00:51<00:00,  4.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.44\n",
      "===> val loss: 0.47, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 127\n",
      "learning rate: 0.00020185224423397574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:34<00:00,  1.21s/it]\n",
      "100%|██████████| 11/11 [00:51<00:00,  4.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.45\n",
      "===> val loss: 0.46, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 128\n",
      "learning rate: 0.0001993619417846922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:32<00:00,  1.19s/it]\n",
      "100%|██████████| 11/11 [00:51<00:00,  4.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.45\n",
      "===> val loss: 0.47, val iou: 0.80\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 129\n",
      "learning rate: 0.0001968681780620511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:33<00:00,  1.20s/it]\n",
      "100%|██████████| 11/11 [00:50<00:00,  4.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.45\n",
      "===> val loss: 0.48, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 130\n",
      "learning rate: 0.00019437089939938174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:31<00:00,  1.18s/it]\n",
      "100%|██████████| 11/11 [00:51<00:00,  4.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.44\n",
      "===> val loss: 0.48, val iou: 0.80\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 131\n",
      "learning rate: 0.0001918700505187031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:33<00:00,  1.20s/it]\n",
      "100%|██████████| 11/11 [00:51<00:00,  4.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.45\n",
      "===> val loss: 0.47, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 132\n",
      "learning rate: 0.00018936557445826965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:31<00:00,  1.18s/it]\n",
      "100%|██████████| 11/11 [00:50<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.45\n",
      "===> val loss: 0.48, val iou: 0.80\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 133\n",
      "learning rate: 0.00018685741249574434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:34<00:00,  1.20s/it]\n",
      "100%|██████████| 11/11 [00:51<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.44\n",
      "===> val loss: 0.50, val iou: 0.80\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 134\n",
      "learning rate: 0.00018434550406666597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:37<00:00,  1.23s/it]\n",
      "100%|██████████| 11/11 [00:52<00:00,  4.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.45\n",
      "===> val loss: 0.47, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 135\n",
      "learning rate: 0.0001818297866778471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:34<00:00,  1.20s/it]\n",
      "100%|██████████| 11/11 [00:50<00:00,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.45\n",
      "===> val loss: 0.46, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 136\n",
      "learning rate: 0.00017931019581530385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:33<00:00,  1.20s/it]\n",
      "100%|██████████| 11/11 [00:49<00:00,  4.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.44\n",
      "===> val loss: 0.47, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 137\n",
      "learning rate: 0.00017678666484628193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:33<00:00,  1.20s/it]\n",
      "100%|██████████| 11/11 [00:51<00:00,  4.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.44\n",
      "===> val loss: 0.45, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 138\n",
      "learning rate: 0.0001742591249149002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:33<00:00,  1.20s/it]\n",
      "100%|██████████| 11/11 [00:50<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.44\n",
      "===> val loss: 0.48, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 139\n",
      "learning rate: 0.00017172750483088596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:33<00:00,  1.20s/it]\n",
      "100%|██████████| 11/11 [00:51<00:00,  4.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.44\n",
      "===> val loss: 0.47, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 140\n",
      "learning rate: 0.00016919173095082495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:34<00:00,  1.20s/it]\n",
      "100%|██████████| 11/11 [00:51<00:00,  4.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.44\n",
      "===> val loss: 0.50, val iou: 0.80\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 141\n",
      "learning rate: 0.00016665172705128707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:34<00:00,  1.21s/it]\n",
      "100%|██████████| 11/11 [00:51<00:00,  4.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.43\n",
      "===> val loss: 0.47, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 142\n",
      "learning rate: 0.00016410741419312688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:32<00:00,  1.19s/it]\n",
      "100%|██████████| 11/11 [00:50<00:00,  4.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.43\n",
      "===> val loss: 0.49, val iou: 0.80\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 143\n",
      "learning rate: 0.00016155871057618057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:33<00:00,  1.20s/it]\n",
      "100%|██████████| 11/11 [00:51<00:00,  4.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.44\n",
      "===> val loss: 0.47, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 144\n",
      "learning rate: 0.00015900553138349974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:32<00:00,  1.19s/it]\n",
      "100%|██████████| 11/11 [00:51<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.42\n",
      "===> val loss: 0.46, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 145\n",
      "learning rate: 0.00015644778861416783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:33<00:00,  1.20s/it]\n",
      "100%|██████████| 11/11 [00:50<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.42\n",
      "===> val loss: 0.47, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 146\n",
      "learning rate: 0.00015388539090363925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:33<00:00,  1.20s/it]\n",
      "100%|██████████| 11/11 [00:50<00:00,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.44\n",
      "===> val loss: 0.47, val iou: 0.80\n",
      "=> saving checkpoint\n",
      "Starting epoch 147\n",
      "learning rate: 0.00015131824333042122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:34<00:00,  1.20s/it]\n",
      "100%|██████████| 11/11 [00:51<00:00,  4.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.43\n",
      "===> val loss: 0.47, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 148\n",
      "learning rate: 0.00014874624720778262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:33<00:00,  1.20s/it]\n",
      "100%|██████████| 11/11 [00:50<00:00,  4.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.43\n",
      "===> val loss: 0.47, val iou: 0.81\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 149\n",
      "learning rate: 0.00014616929985901934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:34<00:00,  1.21s/it]\n",
      "100%|██████████| 11/11 [00:51<00:00,  4.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.43\n",
      "===> val loss: 0.48, val iou: 0.80\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 150\n",
      "learning rate: 0.00014358729437462936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 92/128 [01:51<00:43,  1.21s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-681a5368106f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbegin_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/manan/Projects/EmbedSeg/EmbedSeg/train.py\u001b[0m in \u001b[0;36mbegin_training\u001b[0;34m(train_dataset_dict, val_dataset_dict, model_dict, loss_dict, configs, color_map)\u001b[0m\n\u001b[1;32m    515\u001b[0m                 train_loss = train_3d(virtual_batch_multiplier=train_dataset_dict['virtual_batch_multiplier'],\n\u001b[1;32m    516\u001b[0m                                       \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'one_hot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m                                       n_sigma=loss_dict['lossOpts']['n_sigma'], args=loss_dict['lossW'])\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'virtual_batch_multiplier'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                 train_loss = train_vanilla_3d(display=configs['display'],\n",
      "\u001b[0;32m/mnt/manan/Projects/EmbedSeg/EmbedSeg/train.py\u001b[0m in \u001b[0;36mtrain_3d\u001b[0;34m(virtual_batch_multiplier, one_hot, n_sigma, args)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mvirtual_batch_multiplier\u001b[0m  \u001b[0;31m# Normalize our loss (if averaged)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/Softwares/miniconda3/envs/EmbedSegEnv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/Softwares/miniconda3/envs/EmbedSegEnv/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/Softwares/miniconda3/envs/EmbedSegEnv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/manan/Projects/EmbedSeg/EmbedSeg/criterions/my_loss_3d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, prediction, instances, labels, center_images, w_inst, w_var, w_seed, iou, iou_meter)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mcenter_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_mask\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mcenter_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcenter_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                     \u001b[0mcenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxyzm_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcenter_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyzm_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0mxyz_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxyzm_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0min_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyzm_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TODO --> should this edge case change!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "begin_training(train_dataset_dict, val_dataset_dict, model_dict, loss_dict, configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "  Common causes for errors during training, may include : <br>\n",
    "    1. Not having <b>center images</b> for  <b>both</b> train and val directories  <br>\n",
    "    2. <b>Mismatch</b> between type of center-images saved in <b>01-data.ipynb</b> and the type of center chosen in this notebook (see the <b><a href=\"#center\"> center</a></b> parameter in the third code cell in this notebook)   <br>\n",
    "    3. In case of resuming training from a previous checkpoint, please ensure that the model weights are read from the correct directory, using the <b><a href=\"#resume\"> resume_path</a></b> parameter. Additionally, please ensure that the <b>save_dir</b> parameter for saving the model weights points to a relevant directory. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
