{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import os\n",
    "from EmbedSeg.utils.preprocess_data import extract_data, split_train_val\n",
    "from EmbedSeg.utils.generate_crops import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data'\n",
    "project_name = 'dsb-2018'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, <b>*.tif</b>-type images and the corresponding masks should be respectively present under <b>images</b> and <b>masks</b>, under directories <b>train</b>, <b>val</b> and <b>test</b>, which can be present at any location on your workstation, pointed to by the variable <i>data_dir</i>. (In order to prepare such instance masks, one could use the Fiji plugin <b>Labkit</b> as detailed <b>[here](https://github.com/juglab/EmbedSeg/wiki/Use-Labkit-to-prepare-instance-masks)</b>). The following would be the desired structure as to how data should be present. \n",
    "\n",
    "```\n",
    "$data_dir\n",
    "└───$project-name\n",
    "    |───train\n",
    "        └───images\n",
    "            └───X0.tif\n",
    "            └───...\n",
    "            └───Xn.tif\n",
    "        └───masks\n",
    "            └───Y0.tif\n",
    "            └───...\n",
    "            └───Yn.tif\n",
    "    |───val\n",
    "        └───images\n",
    "            └───...\n",
    "        └───masks\n",
    "            └───...\n",
    "    |───test\n",
    "        └───images\n",
    "            └───...\n",
    "        └───masks\n",
    "            └───...\n",
    "```\n",
    "\n",
    "If you already have your data available in the above style, please skip to the <b><a href=\"#center\">third</a></b> section of this notebook, where you specify the kind of center to which constitutive pixels of an object should embed. \n",
    "Since for the <b> dsb-2018</b> dataset, we do not have the data in this format yet, we firstly download the data from an external url in the following cells, next we split this data to create our `train`, `val` and `test` directories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images and corresponding masks are downloaded from an external url, specified by `zip_url` to the path specified by the variables `data_dir` and `project_name`. The following structure is generated after executing the `extract_data` method below:\n",
    "\n",
    "```\n",
    "data\n",
    "└───dsb-2018\n",
    "    |───download\n",
    "        |───train\n",
    "        |───test\n",
    "    |───dsb-2018.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "extract_data(\n",
    "    zip_url = 'https://github.com/juglab/EmbedSeg/releases/download/v0.1.0/dsb-2018.zip',\n",
    "    data_dir = data_dir,\n",
    "    project_name = project_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into `train`, `val` \\& `test`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we would like to reserve a small fraction (15 % by default) of the provided train dataset as validation data. Here, in case you would like to repeat multiple experiments with the same partition, you may continue and press <kbd>Shift</kbd> + <kbd>Enter</kbd> on the next cell - but in case, you would like different partitions each time, please add the `seed` attribute equal to a different integer (For example, \n",
    "```\n",
    "split_train_val(\n",
    "data_dir = data_dir, \n",
    "project_name = project_name, \n",
    "train_val_name = 'train', \n",
    "subset = 0.15, \n",
    "seed = 1000)\n",
    "```\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Val-Test Images/Masks copied to ../../data/dsb-2018\n"
     ]
    }
   ],
   "source": [
    "split_train_val(\n",
    "    data_dir = data_dir,\n",
    "    project_name = project_name, \n",
    "    train_val_name = 'train',\n",
    "    subset = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify desired centre location for spatial embedding of pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interior pixels of an object instance can either be embedded at the `centroid` (evaluated in $\\mathcal{O(n)}$ operations, where $\\mathcal{n}$ is the number of pixels in an object instance), or the `approximate-medoid` (also evaluated in $\\mathcal{O(n)}$ operations) or the `medoid` (evaluated in $\\mathcal{O(n^{2})}$ operations). Please note that evaluating `medoid` of the instances could be slow especially if you choose a large `crop_size` later: in such a scenario, a quicker alternative is opting for the `approximate-medoid` option, which gives comparable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial Embedding Location chosen as : centroid\n"
     ]
    }
   ],
   "source": [
    "center = 'centroid' # 'centroid', 'approximate-medoid', 'medoid'\n",
    "try:\n",
    "    assert center in {'medoid', 'approximate-medoid', 'centroid'}\n",
    "    print(\"Spatial Embedding Location chosen as : {}\".format(center))\n",
    "except AssertionError as e:\n",
    "    e.args += ('Please specify center as one of : {\"medoid\", \"approximate-medoid\", \"centroid\"}', 42)\n",
    "    raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify cropping configuration parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images and the corresponding masks are cropped into patches centred around an object instance, which are pre-saved prior to initiating the training. Here, `data_subsets` is a list of names of directories which is processed. <br>\n",
    "Note that the cropped images, masks and center-images would be saved at the path specified by `crops_dir` (The parameter `crops_dir` is set to ```./crops``` by default, which creates a directory at the same location as this notebook). Please set `one_hot = True` in case the instances are encoded in a one-hot style. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_dir = './crops'\n",
    "data_subsets = ['train', 'val'] \n",
    "crop_size = 256\n",
    "one_hot = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Crops\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "    The cropped images and masks are saved at the same-location as the example notebooks. <br>\n",
    "    Generating the crops would take a little while!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/380 [00:00<00:51,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new directory : ./crops/dsb-2018/train/images/\n",
      "Created new directory : ./crops/dsb-2018/train/masks/\n",
      "Created new directory : ./crops/dsb-2018/train/center-centroid/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [03:55<00:00,  1.61it/s]\n",
      "  3%|▎         | 2/67 [00:00<00:06, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping of images, instances and centre_images for data_subset = `train` done!\n",
      "Created new directory : ./crops/dsb-2018/val/images/\n",
      "Created new directory : ./crops/dsb-2018/val/masks/\n",
      "Created new directory : ./crops/dsb-2018/val/center-centroid/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:33<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping of images, instances and centre_images for data_subset = `val` done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for data_subset in data_subsets:\n",
    "    image_dir = os.path.join(data_dir, project_name, data_subset, 'images')\n",
    "    instance_dir = os.path.join(data_dir, project_name, data_subset, 'masks')\n",
    "    image_names = sorted(glob(os.path.join(image_dir, '*.tif'))) \n",
    "    instance_names = sorted(glob(os.path.join(instance_dir, '*.tif')))  \n",
    "    for i in tqdm(np.arange(len(image_names))):\n",
    "        if one_hot:\n",
    "            process_one_hot(image_names[i], instance_names[i], os.path.join(crops_dir, project_name), data_subset, crop_size, center, one_hot = one_hot)\n",
    "        else:\n",
    "            process(image_names[i], instance_names[i], os.path.join(crops_dir, project_name), data_subset, crop_size, center, one_hot=one_hot)\n",
    "    print(\"Cropping of images, instances and centre_images for data_subset = `{}` done!\".format(data_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EmbedSegEnv",
   "language": "python",
   "name": "embedsegenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
