{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EmbedSeg.utils.create_dicts import create_test_configs_dict\n",
    "from EmbedSeg.test import begin_evaluating\n",
    "from glob import glob\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "from EmbedSeg.utils.visualize import visualize_3d\n",
    "import os\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the path to the evaluation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation images shall be read from: ../../../data/Platynereis-ISH-Nuclei-CBG\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../../data'\n",
    "project_name = 'Platynereis-ISH-Nuclei-CBG'\n",
    "print(\"Evaluation images shall be read from: {}\".format(os.path.join(data_dir, project_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify evaluation parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hints:\n",
    "* `tta`: Setting this to True (default) would enable **test-time augmentation**\n",
    "* `ap_val`: This parameter (\"average precision value\") comes into action if ground truth segmentations exist for evaluation images, and allows to compare how good our predictions are versus the available ground truth segmentations.\n",
    "* `checkpoint_path`: This parameter provides the path to the trained model weights which you would like to use for evaluation. One could test the pretrained model to get a quick glimpse on the results.\n",
    "* `save_dir`: This parameter specifies the path to the prediction instances. Equal to `inference` by default.\n",
    "In the cell after this one, a `test_configs` dictionary is generated from the parameters specified here!\n",
    "<a id='checkpoint'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment for the model trained by you\n",
    "checkpoint_path = os.path.join('experiment', project_name+'-'+'demo', 'best_iou_model.pth')\n",
    "if os.path.isfile('data_properties.json'): \n",
    "    with open('data_properties.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        one_hot = data['one_hot']\n",
    "        data_type = data['data_type']\n",
    "        min_object_size = int(data['min_object_size'])\n",
    "        foreground_weight = float(data['foreground_weight'])\n",
    "        n_z, n_y, n_x = int(data['n_z']), int(data['n_y']), int(data['n_x'])\n",
    "        pixel_size_z_microns, pixel_size_y_microns, pixel_size_x_microns = float(data['pixel_size_z_microns']), float(data['pixel_size_y_microns']), float(data['pixel_size_x_microns']) \n",
    "        avg_background_intensity = float(data['avg_background_intensity'])\n",
    "if os.path.isfile('normalization.json'): \n",
    "    with open('normalization.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        norm = data['norm']\n",
    "\n",
    "\n",
    "# use the following for the pretrained model weights\n",
    "# checkpoint_path = os.path.join('../../../pretrained_models', project_name, 'best_iou_model.pth')\n",
    "# if os.path.isfile(os.path.join('../../../pretrained_models', project_name,'data_properties.json')): \n",
    "#     with open(os.path.join('../../../pretrained_models', project_name, 'data_properties.json')) as json_file:\n",
    "#         data = json.load(json_file)\n",
    "#         one_hot = data['one_hot']\n",
    "#         data_type = data['data_type']\n",
    "#         min_object_size = int(data['min_object_size'])\n",
    "#         foreground_weight = float(data['foreground_weight'])\n",
    "#         n_z, n_y, n_x = int(data['n_z']),int(data['n_y']), int(data['n_x'])\n",
    "#         pixel_size_z_microns, pixel_size_y_microns, pixel_size_x_microns = float(data['pixel_size_z_microns']), float(data['pixel_size_y_microns']), float(data['pixel_size_x_microns']) \n",
    "#         avg_background_intensity = float(data['avg_background_intensity'])\n",
    "        \n",
    "# if os.path.isfile(os.path.join('../../../pretrained_models', project_name,'normalization.json')): \n",
    "#     with open(os.path.join('../../../pretrained_models', project_name, 'normalization.json')) as json_file:\n",
    "#         data = json.load(json_file)\n",
    "#         norm = data['norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta = False\n",
    "ap_val = 0.5\n",
    "save_dir = './inference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model weights found at : experiment/Platynereis-ISH-Nuclei-CBG-demo/best_iou_model.pth\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"Trained model weights found at : {}\".format(checkpoint_path))\n",
    "else:\n",
    "    print(\"Trained model weights were not found at the specified location!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `test_configs` dictionary from the above-specified parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`test_configs` dictionary successfully created with: \n",
      " -- evaluation images accessed from ../../../data/Platynereis-ISH-Nuclei-CBG, \n",
      " -- trained weights accessed from experiment/Platynereis-ISH-Nuclei-CBG-demo/best_iou_model.pth, \n",
      " -- output directory chosen as ./inference\n"
     ]
    }
   ],
   "source": [
    "test_configs = create_test_configs_dict(data_dir = os.path.join(data_dir, project_name),\n",
    "                                        checkpoint_path = checkpoint_path,\n",
    "                                        tta = tta, \n",
    "                                        ap_val = ap_val,\n",
    "                                        min_object_size = min_object_size, \n",
    "                                        save_dir = save_dir,\n",
    "                                        norm = norm, \n",
    "                                        data_type = data_type,\n",
    "                                        one_hot = one_hot,\n",
    "                                        n_z = n_z,\n",
    "                                        n_y = n_y,\n",
    "                                        n_x = n_x,\n",
    "                                        anisotropy_factor = pixel_size_z_microns/pixel_size_x_microns,\n",
    "                                        name = '3d_sliced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher the Average Precision ($AP_{dsb}$) score is, the better the network has learnt to perform instance segmentation on these unseen images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_evaluating(test_configs, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "  Common causes for an error is: <br>\n",
    "    1. Accessing the model weights at the wrong location. Simply editing the <b> checkpoint_path</b> would fix the issue. <br>\n",
    "    2. CUDA error: out of memory - ensure that you shutdown <i>02-train.ipynb</i> notebook before running this notebook. <br>\n",
    "    3. No test images available\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate some qualitative results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can investigate some quantitative predictions. GT segmentations and predictions, if they exist, are loaded from sub-directories under `save_dir`.\n",
    "Simply change `index` to show the prediction for a random index.\n",
    "Going top-bottom is \n",
    "\n",
    "    * the raw-image which needs to be segmented, \n",
    "    * the corresponding ground truth instance mask, \n",
    "    * the network predicted instance mask, and \n",
    "    * the confidence map predicted by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_file_names = sorted(glob(os.path.join(save_dir,'predictions','*.tif')))\n",
    "ground_truth_file_names = sorted(glob(os.path.join(save_dir,'ground-truth','*.tif')))\n",
    "image_file_names = sorted(glob(os.path.join(data_dir, project_name, 'test', 'images','*.tif')))\n",
    "seed_file_names = sorted(glob(os.path.join(save_dir, 'seeds','*.tif')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cmp= np.load('../../../cmaps/cmap_60.npy')\n",
    "new_cmp = ListedColormap(new_cmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "print(\"Image filename is {} and index is {}\".format(os.path.basename(image_file_names[index]), index))\n",
    "\n",
    "visualize_3d(image_file_names[index], ground_truth_file_names[index], prediction_file_names[index], seed_file_names[index], new_cmp, anisotropy=pixel_size_z_microns/pixel_size_x_microns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
